# 11.2 — **CSS vs XPath** (cours complet, ultra-pratique)

> Objectif : savoir **choisir** et **écrire** le bon sélecteur au bon moment, en Scrapy/Parsel, BeautifulSoup+lxml, ou directement dans vos tests (Scrapy Shell).
> À la fin, vous saurez convertir un sélecteur **CSS → XPath** (et l’inverse), éviter les pièges, et écrire des requêtes **expressives et robustes**.

---

## 1) Quand utiliser **CSS** ? Quand préférer **XPath** ?

**CSS — par défaut (lisible et suffisant dans 80 % des cas)**

* Extraire des éléments **par balise**, **classe**, **id**, **attribut**, **hiérarchie** (descendant/enfant), et pseudo-classes structurelles simples.
* Idéal pour **cartes produits/listes** : `.product .title::text`, `ul > li > a::attr(href)`
* Très lisible, **rapide à mettre au point** (Scrapy Shell / DevTools).
* Dans Scrapy, on ajoute `::text` / `::attr(name)` pour obtenir directement le texte/l’attribut.

**XPath — pour les cas “expressifs/complexes”**

* Sélections **conditionnelles** sur le **texte** (`contains()`, `starts-with()`, `normalize-space()`, comparaison numérique).
* Navigation dans **tous les axes** (↑ **remonter** au parent, aller aux **frères** suivants/précédents, etc.).
* **Positions** avancées : `position()`, `last()`, filtrages contextuels complexes.
* Quand CSS n’a pas d’équivalent (ex. *sélectionner le parent qui contient tel texte enfant*).

> Règle simple : **CSS d’abord** (lisibilité), **XPath** lorsqu’il faut **remonter** dans l’arbre, **filtrer par texte**, ou faire de la **logique** plus fine.

---

## 2) Rappels de **syntaxe** essentiels

### 2.1 CSS (ce qui marche en scraping)

* **Balise** : `div`, `a`, `img`
* **Classe** : `.product`, `.price.color` (plusieurs classes)
* **ID** : `#main`
* **Hiérarchie** :

  * Descendant (à n’importe quelle profondeur) : `div .price`
  * **Enfant direct** : `ul > li > a`
* **Attributs** :

  * Présence : `a[href]`
  * Égalité : `a[rel="nofollow"]`
  * Contient : `a[href*="/promo/"]`
  * Préfixe : `img[src^="https://"]`
  * Suffixe : `img[src$=".jpg"]`
* **Pseudo** (support courant via lxml.cssselect) :

  * `:nth-child(n)`, `:nth-of-type(n)`, `:first-child`, `:last-child`
  * **Pas** de `:contains()` (c’est du jQuery), **pas** de sélection du parent via `:has()` dans la plupart des libs (dont Scrapy/Parsel).
* **Dans Scrapy/Parsel** :

  * `::text` pour le texte, `::attr(href)` pour un attribut.
  * Ex. `response.css('h3 a::attr(title)')`, `response.css('.price::text')`.

### 2.2 XPath (expressivité maximale)

* **Chemins** : `//div` (partout), `./a` (enfant relatif), `/html/body/div` (absolu)
* **Filtre** : `//a[@href]`, `//img[starts-with(@src,"https://")]`
* **Texte** : `//p[contains(., "Promo")]`, `//span[normalize-space()="En stock"]`
* **Attribut** : `//a[@rel="nofollow"]/text()`, `//a/@href`
* **Axes** :

  * Parent : `..` ou `parent::*`
  * Frère suivant : `following-sibling::div[1]`
  * Frère précédent : `preceding-sibling::li[1]`
  * Descendants/ancêtres : `descendant::`, `ancestor::`
* **Positions** : `[1]`, `[last()]`, `[position()<=3]`

---

## 3) **Cheat-sheet** de conversion **CSS ↔ XPath**

| Intention              | CSS                                | XPath                                                                        |
| ---------------------- | ---------------------------------- | ---------------------------------------------------------------------------- |
| Tous les `<a>`         | `a`                                | `//a`                                                                        |
| `<a>` avec `href`      | `a[href]`                          | `//a[@href]`                                                                 |
| `<img>` `.thumb`       | `img.thumb`                        | `//img[contains(concat(" ",normalize-space(@class)," ")," thumb ")]`         |
| ID `main`              | `#main`                            | `//*[@id="main"]`                                                            |
| Descendant             | `div .price`                       | `//div//*/[@class="price"]` *(mieux :)* `//div//*[contains(@class,"price")]` |
| Enfant direct          | `ul > li > a`                      | `//ul/li/a`                                                                  |
| Attribut =             | `a[rel="nofollow"]`                | `//a[@rel="nofollow"]`                                                       |
| Attribut **contient**  | `a[href*="/promo/"]`               | `//a[contains(@href,"/promo/")]`                                             |
| Attribut **préfixe**   | `img[src^="https://"]`             | `//img[starts-with(@src,"https://")]`                                        |
| Attribut **suffixe**   | `img[src$=".jpg"]`                 | `//img[substring(@src, string-length(@src)-3) = ".jpg"]`                     |
| Texte exact            | *(pas d’équivalent natif)*         | `//span[normalize-space()="En stock"]`                                       |
| Texte contient         | *(pas d’équivalent natif)*         | `//p[contains(., "Promotion")]`                                              |
| Premier enfant         | `ul > li:first-child`              | `//ul/li[1]`                                                                 |
| Dernier                | `ul > li:last-child`               | `//ul/li[last()]`                                                            |
| N-ième                 | `ul > li:nth-child(3)`             | `//ul/li[3]`                                                                 |
| **Remonter** au parent | *(CSS n’a pas de parent selector)* | `//a[@class="buy"]/parent::div`                                              |

> Remarque classes : en XPath, `@class` peut contenir plusieurs classes. Utilisez l’astuce `contains(concat(" ", normalize-space(@class), " "), " className ")` pour éviter les faux positifs (ex. `price` vs `pricetag`).

---

## 4) **Cas concrets** (avec HTML mini) — côté **CSS** *et* **XPath**

### 4.1 Carte produit simple

```html
<article class="product">
  <h3><a href="/p/42" title="Laptop Pro 15">Laptop Pro 15</a></h3>
  <p class="price price_color">999.99 €</p>
  <p class="instock availability">En stock</p>
</article>
```

* **Titre (attribut `title`)**

  * CSS : `article.product h3 a::attr(title)`
  * XPath : `//article[contains(@class,"product")]//h3/a/@title`
* **Prix (texte)**

  * CSS : `article.product .price_color::text`
  * XPath : `//article[contains(@class,"product")]//p[contains(@class,"price_color")]/text()`
* **Disponibilité = “En stock” (texte exact)**

  * CSS : *(pas de test de texte natif)* → extraire le texte et tester en Python
  * XPath **direct** : `//p[contains(@class,"instock") and normalize-space()="En stock"]`

### 4.2 Pagination (suivre “next”)

```html
<ul class="pager">
  <li class="next"><a href="page-2.html">next</a></li>
</ul>
```

* **Lien next (href)**

  * CSS : `ul.pager li.next a::attr(href)`
  * XPath : `//ul[contains(@class,"pager")]//li[contains(@class,"next")]/a/@href`

### 4.3 Sélection **par texte** (promo)

```html
<div class="badge">PROMO -20%</div>
```

* CSS : *(non, pas de `:contains()`) → récupérez le texte et filtrez côté Python*
* XPath : `//div[contains(@class,"badge")][contains(., "PROMO")]`

### 4.4 **Remonter** du lien au conteneur

```html
<div class="tile">
  <a class="buy" href="/cart?item=42">Acheter</a>
</div>
```

* **Le conteneur `.tile` à partir de `<a.buy>`**

  * CSS : *impossible* (pas de sélection du parent)
  * XPath : `//a[contains(@class,"buy")]/ancestor::div[contains(@class,"tile")][1]`

---

## 5) **Scrapy/Parsel** : API pratiques & astuces

* **Extraction**

  * CSS : `response.css('h3 a::attr(title)').getall()`
  * XPath : `response.xpath('//h3/a/@title').getall()`
* **Chaînage**

  * `response.css('article.product').css('h3 a::text').get()` (chaîne de contexte)
* **Regex** (après extraction)

  * `response.css('.price_color::text').re(r'\d+[\.,]\d+')`
* **Nettoyage**

  * `response.xpath('normalize-space(//p[@class="instock availability"])').get()`
* **Debug**

  * `scrapy shell URL` → tester rapidement sélecteurs, comparer CSS vs XPath.

---

## 6) **BeautifulSoup** (CSS) vs **lxml.html** (XPath)

* **BeautifulSoup** : `soup.select('article.product .price::text')` (CSS seulement).

  * Pas d’XPath natif ; pour XPath, passez par **lxml.html**.
* **lxml.html** : `root.xpath('//article[contains(@class,"product")]//p[@class="price"]')`.
* **Mélanger** BS4 + lxml est possible, mais en projet **Scrapy**, utilisez **Parsel** (CSS & XPath) de manière uniforme.

---

## 7) **Robustesse** & **performance** des sélecteurs

* **Spécificité stable** : ancrez sur des **classes/id sémantiques** (`.product-card`, `.price`) ou mieux sur des **attributs “data-*”** (`[data-qa="price"]`) quand disponibles.
* **Évitez** les sélecteurs **fragiles** (indices numériques, classes obfusquées, profondeurs excessives).
* **Court et explicite** > long et hyper-spécifique.
* **Performance** : CSS est **traduit** en XPath par lxml.cssselect → en pratique, **peu de différence**. Le goulot est souvent réseau/parsing, pas le matching.
* **Normalisez** le **texte** côté XPath (`normalize-space()`) ou côté Python (strip, remplacements) pour éviter les surprises.

---

## 8) **Pièges classiques** (et comment les éviter)

1. **Classes multiples** : `class="price price_color"`

   * CSS : `.price.price_color` ok.
   * XPath : utilisez le **truc** avec `contains(concat(" ", normalize-space(@class), " "), " price ")`.
2. **Pas de `:contains()` en CSS**

   * C’est jQuery-only. Utilisez XPath `contains(., "texte")` ou filtrez en Python.
3. **Sélection du parent en CSS**

   * `:has()` non supporté dans les libs courantes → **XPath** `parent::`/`ancestor::`.
4. **Positions**

   * CSS `:nth-child(n)` vs XPath `[n]` ; attention aux nœuds texte/commentaires en XPath si l’HTML est “sale”.
5. **Attribut “suffixe” en XPath**

   * Pas d’opérateur direct → utilisez `substring()`/`string-length()` ou comparez un `contains()` + fin stricte en Python.
6. **Espaces/retours ligne**

   * `normalize-space()` en XPath ; en CSS, récupérez le texte et nettoyez côté Python.
7. **Locales/prix**

   * Extraire **le nombre** via regex (`re()`) après `.get()`/`.getall()` pour uniformiser (virgule/point).

---

## 9) **Mini-atelier** (avec solutions)

HTML d’exemple :

```html
<ul id="products">
  <li class="item featured">
    <h3><a href="/prod/100" title="Ultra Phone X">Ultra Phone X</a></h3>
    <span class="price">1 099,00 €</span>
    <span class="badge">NOUVEAU</span>
  </li>
  <li class="item">
    <h3><a href="/prod/101" title="SmartCam 4K">SmartCam 4K</a></h3>
    <span class="price">199,90 €</span>
  </li>
</ul>
```

**Q1.** Récupérer **tous les titres** (texte du lien)

* CSS : `#products li.item h3 a::text`
* XPath : `//*[@id="products"]//li[contains(@class,"item")]//h3/a/text()`

**Q2.** Récupérer les **href** des liens produits

* CSS : `#products li.item h3 a::attr(href)`
* XPath : `//*[@id="products"]//li[contains(@class,"item")]//h3/a/@href`

**Q3.** Récupérer le **prix** des items **featured uniquement**

* CSS : `#products li.item.featured .price::text`
* XPath : `//*[@id="products"]//li[contains(concat(" ",normalize-space(@class)," ")," item ") and contains(concat(" ",normalize-space(@class)," ")," featured ")]//span[contains(@class,"price")]/text()`

**Q4.** Vérifier si la **badge** contient le mot “NOUVEAU” (XPath direct)

* XPath : `boolean(//*[@id="products"]//span[contains(@class,"badge")][contains(., "NOUVEAU")])`

---

## 10) **Décision rapide** (mémo)

* **Je veux les attributs/texte d’éléments balisés clairement** → **CSS**
* **Je dois filtrer par texte, ou remonter/aller aux frères** → **XPath**
* **Je dois convertir ou nettoyer du texte** → `normalize-space()` (XPath) ou Python (post-traitement)
* **Je teste** → Scrapy Shell (`scrapy shell URL`), j’essaie **CSS**, puis **XPath** si nécessaire

---

### Conclusion

* **CSS** : rapide, lisible, suffisant pour la majorité des extractions **structurales**.
* **XPath** : votre **couteau suisse** pour les cas avancés (texte, axes, positions).
* Savoir **convertir** l’un en l’autre vous rend **plus rapide**, **plus robuste** et **plus précis**.
* Dans un projet pro, **standardisez** des patrons (snippets) et un **style guide** de sélecteurs pour votre équipe (préfixes data-*, normalisation, tests systématiques dans le Shell).
